{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./config.yml', 'rb') as yml:\n",
    "    config = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name =config['repo_name']\n",
    "name='fw07' #'atr503','eval1','eval2','eval3','jdrt, fw07'\n",
    "\n",
    "target=config['target'] # target token name\n",
    "sr=config['sr']\n",
    "test_csv='./datasets/test_'+name+'_'+target+'.csv'\n",
    "result_path='./results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://note.mjunya.com/posts/2021-12-13-multi-gpu-order/\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=config['CUDA_VISIBLE_DEVICES']\n",
    "!echo ${CUDA_VISIBLE_DEVICES}\n",
    "\n",
    "import torch\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    print(f\"CUDA:{i} {info.name}, {info.total_memory / 1024 ** 2}MB\")\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(f\"version: {torch.__version__}\")\n",
    "print(f\"available: {torch.cuda.is_available()}\")\n",
    "print(f\"count: {torch.cuda.device_count()}\")\n",
    "for i in range(0,torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_capability(i)}\")\n",
    "print(f\"default: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchaudio, datasets, warnings\n",
    "from datasets import load_dataset, load_metric, Audio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= datasets.load_dataset(\"csv\", data_files={\"test\":[test_csv]},usecols=['path',target],num_proc=config['num_proc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "processor = Wav2Vec2Processor.from_pretrained(repo_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random(test['test'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2array(batch):\n",
    "    array, rate = torchaudio.load(filepath=batch['path'],format=config['format'])\n",
    "    batch[\"audio_array\"]= array\n",
    "    batch[\"sampling_rate\"] =rate\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test=test.map(path2array,num_proc=config['num_proc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change name [\"input_values\"],[\"labels\"]\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    batch[\"input_values\"] = processor(batch[\"audio_array\"], sampling_rate=batch[\"sampling_rate\"]).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[target]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test=test.map(prepare_dataset,num_proc=config['num_proc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2result(batch):\n",
    "  model.to(\"cuda\")\n",
    "  input_values = processor(\n",
    "      batch[\"audio_array\"], \n",
    "      sampling_rate=batch[\"sampling_rate\"], \n",
    "      return_tensors=\"pt\"\n",
    "  ).input_values.to(\"cuda\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    logits=model(input_values).logits\n",
    "\n",
    "  pred_ids = torch.argmax(logits, dim=-1)\n",
    "  batch[\"hypothesis\"] = processor.batch_decode(pred_ids)[0]\n",
    "  \n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2csv(batch):\n",
    "    s=batch['path']\n",
    "    batch['path']=os.path.splitext(os.path.basename(s))[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result=test['test'].map(map2result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.map(result2csv,num_proc=config['num_proc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random(result.remove_columns(['audio_array','labels','input_values','sampling_rate']),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WER&CER\n",
    "result_wer=wer_metric.compute(predictions=result[\"hypothesis\"], references=result[target])\n",
    "result_cer=cer_metric.compute(predictions=result[\"hypothesis\"], references=result[target])\n",
    "print(\"Test WER: {:.3f}\".format(result_wer))\n",
    "print(\"Test CER: {:.3f}\".format(result_cer))\n",
    "\n",
    "path=result_path+'/wer_'+target+'.csv'\n",
    "if not os.path.isfile(path):\n",
    "    with open(path, mode='w')as f:\n",
    "        f.write('dataset,target,wer,cer\\n')\n",
    "\n",
    "list1=[]\n",
    "list1.extend([name,target,result_wer,result_cer])\n",
    "with open(path, mode='a')as f:\n",
    "    f.write((','.join(map(str,list1)))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv & rename \"ID\",\"reference\",\"hypothesis\"\n",
    "result=result.rename_column('path','ID')\n",
    "result=result.rename_column(target,'reference')\n",
    "result.to_csv(result_path+'/result_'+name+'_'+target+'.csv',columns=['ID','reference','hypothesis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "model.to(\"cuda\")\n",
    "a=test[\"test\"][i][\"phone\"]\n",
    "input_values = processor(test[\"test\"][i][\"audio_array\"], sampling_rate=test[\"test\"][i][\"sampling_rate\"], return_tensors=\"pt\").input_values.to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "  logits = model(input_values).logits\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "decoded=processor.decode(pred_ids[0])\n",
    "converted=processor.tokenizer.convert_ids_to_tokens(pred_ids[0].tolist())\n",
    "joined=\" \".join(converted)\n",
    "\n",
    "print(os.path.basename(test[\"test\"][i][\"path\"]))\n",
    "print(f\"target: {a}\")\n",
    "print(f\"token_decode: {decoded}\")\n",
    "print(f\"token_list: {converted}\")\n",
    "print(f\"token_str: {joined}\")\n",
    "print(f\"token_size: {len(converted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker",
   "language": "python",
   "name": "docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
