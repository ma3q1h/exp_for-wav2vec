{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file=\"../results/result_jdrt_phone.csv\"\n",
    "subject_file=\"./sub_gmm_multi.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv(csv_file,sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install japanize-matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"font.size\"] = 25\n",
    "plt.rcParams['figure.figsize'] = (13.0, 11.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1,'drt_no',df['ID'].astype(str).str[:3])\n",
    "df['drt_no'] = df['drt_no'].astype(int)\n",
    "df.insert(2,'person_int',df['ID'].astype(str).str[4])\n",
    "df['person_int'] = df['person_int'].astype(int)\n",
    "df.insert(3,'sex_int',df['ID'].astype(str).str[6])\n",
    "df['sex_int'] = df['sex_int'].astype(int)\n",
    "df.insert(4,'noise_int',df['ID'].astype(str).str[8])\n",
    "df['noise_int'] = df['noise_int'].astype(int)\n",
    "df.insert(5,'snr_int',df['ID'].astype(str).str[10])\n",
    "df['snr_int'] = df['snr_int'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drt_120_openjtalk=['z a i','s a i','d a k u','t a k u','g i j i','k i j i','g i N','k i N','z u i','s u i','g u u','k u u','z e i','s e i','d e b a','t e b a','z o u','s o o','g o j i','k o j i','m a N','b a N','n a i','d a i','m i s u','b i s u','m i r u','b i r u','m u r i','b u r i','m u sh i','b u sh i','m e N','b e N','n e r u','d e r u','m o N','b o N','n o r a','d o r a','h a sh i','k a sh i','h a t a','k a t a','sh i r i','ch i r i','h i r u','k i r u','s U k i','ts U k i','s u n a','ts u n a','h e N','k e N','h e r i','k e r i','h o sh i','k o sh i','h o r u','k o r u','j a m u','g a m u','ch a k u','k a k u','sh I k i','h i k i','ch i j i','k i j i','ch u u','k u u','j u N','g u N','sh e a','h e a','sh e r u','h e r u','j o o','g o o','sh o j i','h o j i','w a k u','r a k u','p a i','t a i','m i e','n i e','m i s u','n i s u','m u k u','n u k u','m u sh i','n u sh i','m a N','n e N','p e N','t e N','m o o','n o o','p o r o','t o r o','y a k u','w a k u','k a i','p a i','g i N','b i N','k i z a','p i z a','k u r o','p u r o','y u u','r u u','g e N','b a N','k e N','p e N','g o k i','b o k i','y o k a','r o k a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = df['reference'].unique()\n",
    "print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sex={2:'male',1:'female'}\n",
    "dic_snr={4:'-15',3:'-10',2:'0',1:'10',0:'clean'}\n",
    "dic_noise={0:'non',1:'babble',2:'brown',3:'pseudo',4:'pink',5:'white'}\n",
    "dic_person={1:'aoki',2:'kanno',3:'moriya',4:'nakamura',5:'minagawa',6:'miura',7:'nagata',8:'suzuki'}\n",
    "dic_consonant={0:'voicing',1:'nasality',2:'sustention',3:'sibilation',4:'graveness',5:'compactness'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(8,'ref_front',df['reference'].str[0])\n",
    "df.insert(9,'hyp_front',df['hypothesis'].str[0])\n",
    "df.insert(10,'ref_theOther',\"\")\n",
    "for index, data in df.iterrows():\n",
    "    drtno_int=df.loc[index,'drt_no']\n",
    "    if drtno_int%2==1:\n",
    "        df.loc[index,'ref_theOther']=drt_120_openjtalk[drtno_int]\n",
    "    elif drtno_int%2==0:\n",
    "        df.loc[index,'ref_theOther']=drt_120_openjtalk[drtno_int-2]\n",
    "\n",
    "df.insert(11,'ref_theOther_front',df['ref_theOther'].str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エラー・2択内・自由回答で出力を分類\n",
    "for index, data in df.iterrows():\n",
    "    ans_kana_front=df.loc[index,'hyp_front']\n",
    "    if ans_kana_front==\" \":\n",
    "        df.loc[index,'txt_kana_free']=\"error\"\n",
    "    elif ans_kana_front==df.loc[index,'ref_front'] or ans_kana_front==df.loc[index,'ref_theOther_front']:\n",
    "        df.loc[index,'txt_kana_free']=df.loc[index,'hyp_front']\n",
    "    else :\n",
    "        df.loc[index,'txt_kana_free']=\"free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consonant\n",
    "df.insert(8,'Consonant',\"\")\n",
    "df.loc[df['drt_no']<=20,'Consonant']=0\n",
    "df.loc[(df['drt_no']>20)&(df['drt_no']<=40),'Consonant']=1\n",
    "df.loc[(df['drt_no']>40)&(df['drt_no']<=60),'Consonant']=2\n",
    "df.loc[(df['drt_no']>60)&(df['drt_no']<=80),'Consonant']=3\n",
    "df.loc[(df['drt_no']>80)&(df['drt_no']<=100),'Consonant']=4\n",
    "df.loc[df['drt_no']>=101,'Consonant']=5\n",
    "df['Consonant']=df['Consonant'].astype(int)\n",
    "\n",
    "#word_pair\n",
    "df.insert(9,'versus',\"\")\n",
    "for index, data in df.iterrows():\n",
    "    temp=df.loc[index,'drt_no'].astype(int)\n",
    "    if temp%2==1:\n",
    "        temp=temp+1\n",
    "    df.loc[index,'versus']=temp//2\n",
    "df['versus']=df['versus'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise限定\n",
    "df=df[df['noise_int']!=2]\n",
    "df=df[df['noise_int']!=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crr:正(1),誤(0),自由回答(乱数),未認識(乱数)??\n",
    "#0:誤答扱い, random:乱数, nan:ノーカウント\n",
    "ERROR=\"random\"\n",
    "FREE=\"random\"\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "df2=df\n",
    "df2['crr']=\"\"\n",
    "for index, data in df2.iterrows():\n",
    "    samp=df.loc[index,'txt_kana_free']\n",
    "    if samp== 'error':\n",
    "        if ERROR==\"0\":\n",
    "            df2.loc[index,'crr']=0\n",
    "        elif ERROR==\"random\":\n",
    "            df2.loc[index,'crr']=random.randint(0, 1)\n",
    "        elif ERROR==\"nan\":\n",
    "            df2.loc[index,'crr']=np.nan\n",
    "    elif samp=='free':\n",
    "        if FREE==\"0\":\n",
    "            df2.loc[index,'crr']=0\n",
    "        elif FREE==\"random\":\n",
    "            df2.loc[index,'crr']=random.randint(0, 1)\n",
    "        elif FREE==\"nan\":\n",
    "            df2.loc[index,'crr']=np.nan\n",
    "    else:\n",
    "        df2.loc[index,'crr'] = np.where(df2.loc[index,'ref_front'] ==df2.loc[index,'txt_kana_free'], 1,0)\n",
    "print(np.unique(df2['crr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null判定を除外 出力は前後\n",
    "print(df.shape)\n",
    "df2=df2[df2['crr'].notnull()]\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ノイズ別了解度算出\n",
    "evaluation=1\n",
    "model='CTC'\n",
    "target='crr'\n",
    "\n",
    "x1='Consonant'\n",
    "y1=\"snr_int\"\n",
    "z1='noise_int'\n",
    "col_name=['evaluation','model','noise','snr','consonant','crr']\n",
    "\n",
    "x=df2[x1].value_counts().to_dict()\n",
    "y=df2[y1].value_counts().to_dict()\n",
    "z=df2[z1].value_counts().to_dict()\n",
    "\n",
    "#result_df= pd.DataFrame()\n",
    "test2_list=[]\n",
    "for i in z.keys():\n",
    "    if i==0: #snrとnoiseの整合性\n",
    "        continue\n",
    "    df_copy=df2[df2['noise_int'].isin([0,i])]\n",
    "    for j in x.keys():\n",
    "        for k in y.keys():\n",
    "            test_list=[]\n",
    "            A=((df_copy[x1]==j)&(df_copy[y1]==k)&(df_copy[target]==1)).sum()\n",
    "            B=((df_copy[x1]==j)&(df_copy[y1]==k)&(df_copy[target]==0)).sum()\n",
    "            C=((df_copy[x1]==j)&(df_copy[y1]==k)).sum()\n",
    "            a=(A-B)/C*100\n",
    "            test_list.append(evaluation)\n",
    "            test_list.append(model)\n",
    "            test_list.append(i)\n",
    "            test_list.append(k)\n",
    "            test_list.append(j)\n",
    "            test_list.append(a)\n",
    "            test2_list.append(test_list)\n",
    "\n",
    "result_df=pd.DataFrame(test2_list)\n",
    "result_df.columns=col_name\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#客観評価を並び替え、データフレームXで定義\n",
    "temp_X= result_df.sort_values(['noise','snr','consonant'])\n",
    "temp=temp_X.reset_index(drop=True)\n",
    "X=temp['crr']\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#主観評価CSVを並び替え、Y定義\n",
    "df_sub=pd.read_csv(subject_file, encoding=\"utf-8\")\n",
    "temp_Y=df_sub[df_sub['model']==0]\n",
    "temp_Y=temp_Y.sort_values(['noise','snr','consonant'])\n",
    "temp=temp_Y.reset_index(drop=True)\n",
    "Y=temp['crr']\n",
    "print(Y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#散布図、ｒ、rmse算出\n",
    "fig = plt.figure()\n",
    "plt.scatter(X, Y)\n",
    "senkei=np.polyfit(X,Y,1)\n",
    "func=np.poly1d(senkei)\n",
    "F=func(X)\n",
    "plt.plot(X, F, label='best-fit line')\n",
    "a=np.corrcoef(X,Y)[0][1]\n",
    "rmse = np.sqrt(mean_squared_error(Y, X))\n",
    "plt.xlabel(\"Objective [%]\")\n",
    "plt.ylabel(\"Subjective [%]\")\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0,100)\n",
    "plt.plot([0, 100], [0, 100], ls=\"--\", c=\".3\", label='equal line')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title(\"wav2vec: r={:.2f}, rmse={:.2f}\".format(a,rmse))\n",
    "\n",
    "print(\"r=%f\"% a)\n",
    "print('rmse=%f'%rmse)\n",
    "\n",
    "fig.savefig(\"./scatter.png\")\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#子音特徴別結果（ノイズ平均）\n",
    "pd.options.display.precision=2\n",
    "target='crr'\n",
    "x1=\"snr_int\"\n",
    "y1='Consonant'\n",
    "\n",
    "x=df2[x1].value_counts().to_dict()\n",
    "y=df2[y1].value_counts().to_dict()\n",
    "gdf=pd.DataFrame(index=x.keys(),columns=y.keys())\n",
    "for i in x.keys():\n",
    "    for j in y.keys():\n",
    "        a=((df2[(df2[y1]==j)&(df2[x1]==i)&(df2[target]==1)].count())-(df2[(df2[y1]==j)&(df2[x1]==i)&(df2[target]==0)].count())) / df2[(df2[x1]==i)&(df2[y1]==j)].count() *100\n",
    "        gdf.at[i,j]=a.iat[0]\n",
    "gdf_s=gdf.sort_index(ascending=False)\n",
    "gdf_s=gdf_s.rename(index=dic_snr)\n",
    "gdf_s=gdf_s.rename(columns=dic_consonant)\n",
    "gdf_s.round(2)\n",
    "gdf_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "gdf_s.plot(title='Correct response rate with wav2vec \\nfor each attribute vs. SNR',xlabel='SNR[dB]',ylabel='correct respnse rate[%]',ylim=[0,100],linewidth=7, marker=\"o\", markersize=15, grid=True)\n",
    "plt.savefig('./consonant.png')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision=2\n",
    "df3=gdf_s.mean(axis='columns')\n",
    "#df3=pd.DataFrame(df3)\n",
    "df3.columns=['ctc']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#単語対での調査\n",
    "target='crr'\n",
    "x1=\"snr_int\"\n",
    "y1='versus'\n",
    "\n",
    "x=df2[x1].value_counts().to_dict()\n",
    "y=df2[y1].value_counts().to_dict()\n",
    "gdf=pd.DataFrame(index=x.keys(),columns=y.keys())\n",
    "for i in x.keys():\n",
    "    for j in y.keys():\n",
    "        a=((df2[(df2[y1]==j)&(df2[x1]==i)&(df2[target]==1)].count())-(df2[(df2[y1]==j)&(df2[x1]==i)&(df2[target]==0)].count())) / df2[(df2[x1]==i)&(df2[y1]==j)].count() *100\n",
    "        gdf.at[i,j]=a.iat[0]\n",
    "gdf=gdf.sort_index(ascending=False)\n",
    "gdf.index=['-15','-10','0','10','clean']\n",
    "gdf.round(2)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.concat([gdf,pd.DataFrame(gdf.mean(axis=0),columns=['mean']).T])\n",
    "gdf.sort_values(by='mean',axis=1, ascending=True, inplace=True)\n",
    "for pair_int in gdf:\n",
    "    re_name=str(pair_int)+\": \"+drt_120_openjtalk[(2*pair_int)-2]+\"-\"+drt_120_openjtalk[(2*pair_int)-1]\n",
    "    gdf.rename(columns={pair_int: re_name}, inplace=True)\n",
    "\n",
    "gdf.loc['mean'].plot.barh(fontsize = 10)\n",
    "plt.title('word-pair (ave.)',fontsize=15)\n",
    "plt.xlabel('CRR[%]',fontsize=15)\n",
    "plt.savefig('./word_pair.png')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker",
   "language": "python",
   "name": "docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
